{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nfrom typing import List\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Inputs\n\n#accuracies = [0.9363,0.9991,0.8213,0.997]\n#training_times = [1662,584,694,277]\n#model_names =[\"CNN 1D-Time\",\"CNN 1D-Frequency\",\"CNN 2D-Time\",\"CNN 2D-Frequency\"]\n\n\naccuracies = [0.8213,0.997]\ntraining_times = [694,277]\nmodel_names =[\"CNN 2D-Time\",\"CNN 2D-Frequency\"]\n\n\n#accuracies = [0.3,0.31,0.78,0.43,0.72,0.45,0.98,0.98]\n#training_times = [796,14226,32,74,31,64,552,383]\n#model_names =[\"RF\",\"SVM\",\"RF + Feat. Ext.\",\"SVM + Feat. Ext.\",\"RF + Feat. Ext. + PCA\",\"SVM + Feat. Ext. + PCA\",\"RF + FFT\",\"SVM + FFT\"]\n\n\n#accuracies = [0.3,0.31,0.78,0.43,0.98,0.98]\n#training_times = [796,14226,32,74,552,383]\n#model_names =[\"RF\",\"SVM\",\"RF + FeatExt\",\"SVM + FeatExt\",\"RF + FFT\",\"SVM + FFT\"]\n\n\nalphas = (0.2, 0.5, 0.7)\n\n\nif not (len(model_names) == len(accuracies) == len(training_times)):\n    raise ValueError(\"model_names, accuracies and training_times should have the same dimension.\")\nif len(model_names) == 0:\n    raise ValueError(\"Gives at leat one model.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute tn (normalized ) model training time of each model\n\ndef normalize_time_log(times: List[float]) -> np.ndarray:\n    \"\"\"\n    t_n in [0,1] via escala log:\n      t_n = (log t - log t_min) / (log t_max - log t_min)\n    Requer t > 0. Se t_min == t_max devolve zeros.\n    \"\"\"\n    times = np.asarray(times, dtype=float)\n    if np.any(times <= 0):\n        raise ValueError(\"Todos os tempos devem ser > 0 para normalização log.\")\n    t_min, t_max = times.min(), times.max()\n    if t_min == t_max:\n        return np.zeros_like(times)\n    tn = (np.log(times) - np.log(t_min)) / (np.log(t_max) - np.log(t_min))\n    return np.clip(tn, 0.0, 1.0)\n\ntn = normalize_time_log(training_times)\nprint(tn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Compute S (Speed of each model)\n\ndef compute_speed_from_tn(tn: np.ndarray) -> np.ndarray:\n    \"\"\"Speed normalizada = 1 - t_n.\"\"\"\n    return 1.0 - tn\n\nspeed = compute_speed_from_tn(tn)\nprint(speed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Compute GPI of each model\n\ndef compute_gpi(acc: List[float], speed: np.ndarray, alphas) -> pd.DataFrame:\n    \"\"\"\n    GPI_alpha = alpha*accuracy + (1-alpha)*speed para cada alpha.\n    acc deve estar em [0,1].\n    \"\"\"\n    acc = np.asarray(acc, dtype=float)\n    if np.any((acc < 0) | (acc > 1)):\n        raise ValueError(\"Todas as accuracies devem estar em [0,1].\")\n    if acc.shape != speed.shape:\n        raise ValueError(\"accuracy e speed devem ter o mesmo comprimento.\")\n    data = {}\n    for a in alphas:\n        if not (0.0 <= a <= 1.0):\n            raise ValueError(\"Cada alpha deve estar em [0,1].\")\n        data[f\"GPI_alpha_{a}\"] = a * acc + (1 - a) * speed\n    return pd.DataFrame(data)\n\ngpi_df = compute_gpi(accuracies, speed, alphas=alphas)\n\n\n#Resume table\nres = pd.DataFrame({\n    \"model\": model_names,\n    \"accuracy\": accuracies,\n    \"time_s\": training_times,\n    \"t_n\": tn,\n    \"Speed\": speed\n}).join(gpi_df)\n\n\nfirst_gpi_col = gpi_df.columns[0]\nres_sorted = res.sort_values(by=first_gpi_col, ascending=False).reset_index(drop=True)\n\nres_sorted","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot (bar chart) the GPI of each model to different values of alpha\n\nx = np.arange(len(model_names))\nwidth = 0.8 / len(gpi_df.columns)\n\nplt.figure(figsize=(10, 6))\nfor i, col in enumerate(gpi_df.columns):\n    offsets = x + (i - (len(gpi_df.columns)-1)/2) * width\n    plt.bar(offsets, gpi_df[col].values, width=width, label=col)\n\nplt.xticks(x, model_names, rotation=25, ha=\"right\")\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.ylabel(\"GPI\")\nplt.title(\"Global Performance Index (GPI) for each CNN model - Dataset I\")\nplt.ylim(0, 1.01)\nplt.legend()\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot (line chart) the GPI of each model to different values of alpha\n\nplt.figure(figsize=(10, 6))\n\n\nx = np.arange(len(model_names))\n\n\nalpha_values = [float(c.split(\"_\")[-1]) for c in gpi_df.columns]\n\nfor j, col in enumerate(gpi_df.columns):\n    plt.plot(\n        x,\n        gpi_df[col].values,\n        marker=\"o\",\n        label=f\"α = {alpha_values[j]}\"\n    )\n\nplt.xticks(x, model_names)\n#plt.xticks(x, model_names, rotation=25, ha=\"right\")\nplt.yticks(np.arange(0, 1.1, 0.1))\nplt.ylabel(\"GPI\")\nplt.title(\"Global Performance Index (GPI) for RF and SVM models - Dataset I\")\nplt.ylim(0, 1.01)\nplt.legend(loc='upper left')\nplt.grid(axis='x', linestyle=\"--\", alpha=0.6)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}