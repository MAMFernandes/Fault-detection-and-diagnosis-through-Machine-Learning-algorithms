{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11869742,"sourceType":"datasetVersion","datasetId":7459206},{"sourceId":12537171,"sourceType":"datasetVersion","datasetId":7914863},{"sourceId":12564627,"sourceType":"datasetVersion","datasetId":7934346}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy.stats import kurtosis, skew\n\nfrom scipy.fft import fft\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\n\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import roc_curve, auc\nfrom itertools import cycle\n\n\nimport seaborn as sns\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.decomposition import PCA\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#File names\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ----------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Input Dataset I","metadata":{}},{"cell_type":"code","source":"\ndata0D = pd.read_csv('/kaggle/input/vibration-dataset-1/0D.csv')\ndata1D = pd.read_csv('/kaggle/input/vibration-dataset-1/1D.csv')\ndata2D = pd.read_csv('/kaggle/input/vibration-dataset-1/2D.csv')\ndata3D = pd.read_csv('/kaggle/input/vibration-dataset-1/3D.csv')\ndata4D = pd.read_csv('/kaggle/input/vibration-dataset-1/4D.csv')\n\ndata0E = pd.read_csv('/kaggle/input/vibration-dataset-1/0E.csv')\ndata1E = pd.read_csv('/kaggle/input/vibration-dataset-1/1E.csv')\ndata2E = pd.read_csv('/kaggle/input/vibration-dataset-1/2E.csv')\ndata3E = pd.read_csv('/kaggle/input/vibration-dataset-1/3E.csv')\ndata4E = pd.read_csv('/kaggle/input/vibration-dataset-1/4E.csv')\n\n\n\nprint('DATASET LOADED')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The signal was initialized from 20 seconds onward to eliminate the initial transient phase.\n\nfs = 4096\ninitial_time = 20 * fs  \n\n\n# Reiniciar Ã­ndice\ndata0D = data0D.iloc[initial_time:].reset_index(drop=True)\ndata1D = data1D.iloc[initial_time:].reset_index(drop=True)\ndata2D = data2D.iloc[initial_time:].reset_index(drop=True)\ndata3D = data3D.iloc[initial_time:].reset_index(drop=True)\ndata4D = data4D.iloc[initial_time:].reset_index(drop=True)\n\n\ndata0E = data0E.iloc[initial_time:].reset_index(drop=True)\ndata1E = data1E.iloc[initial_time:].reset_index(drop=True)\ndata2E = data2E.iloc[initial_time:].reset_index(drop=True)\ndata3E = data3E.iloc[initial_time:].reset_index(drop=True)\ndata4E = data4E.iloc[initial_time:].reset_index(drop=True)\n\n\nprint('Done')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-second window\n\nwindow_time = 1  \nwindow = fs * window_time  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Divide the raw signal in samples of 1 sec and labeling each sample","metadata":{}},{"cell_type":"code","source":"# Extracts signal segments of the specified window size.\n\ndef get_features(data, label):\n    n = int(np.floor(len(data)/window))\n    data = data[:int(n)*window]\n    X = data.values.reshape((n, window))\n    y = np.ones(n)*labels[label]\n    return X,y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = {'no_unbalance':0, 'unbalance_1':1, 'unbalance_2':2,'unbalance_3':3, 'unbalance_4':4}\nsensor = 'Vibration_2'\n\n\nX0D, y0D = get_features(data0D[sensor], \"no_unbalance\")\nX1D, y1D = get_features(data1D[sensor], \"unbalance_1\")\nX2D, y2D = get_features(data2D[sensor], \"unbalance_2\")\nX3D, y3D = get_features(data3D[sensor], \"unbalance_3\")\nX4D, y4D = get_features(data4D[sensor], \"unbalance_4\")\n\n\nX0E, y0E = get_features(data0E[sensor], \"no_unbalance\")\nX1E, y1E = get_features(data1E[sensor], \"unbalance_1\")\nX2E, y2E = get_features(data2E[sensor], \"unbalance_2\")\nX3E, y3E = get_features(data3E[sensor], \"unbalance_3\")\nX4E, y4E = get_features(data4E[sensor], \"unbalance_4\")\n\n\n\nX=np.concatenate([X0D, X1D, X2D, X3D, X4D, X0E, X1E, X2E, X3E, X4E])\nY=np.concatenate([y0D, y1D, y2D, y3D, y4D, y0E, y1E, y2E, y3E, y4E])\n\n\nprint(X.shape, Y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Histogram used to visualize the number of samples per class (to verify whether the dataset is balanced).\n\ncustom_labels = [\n    \"Normal\",\n    \"Unb. I\",\n    \"Unb. II\",\n    \"Unb. III\",\n    \"Unb. IV\"\n]\n\n\nplt.figure(figsize=(8,5))\nplt.hist(Y, bins=np.arange(len(labels)+1)-0.5, edgecolor='black', rwidth=0.8)\n\n\nplt.xticks(range(len(labels)), custom_labels, rotation=0)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Absolute Frequency\")\nplt.title(\"Class Distribution for Dataset I\")\n\nplt.grid(axis='y', linestyle='--', alpha=0.6)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Input Dataset II","metadata":{}},{"cell_type":"code","source":"\n\nfor i in range(1, 1001):\n    globals()[f\"data_normal_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/normal/normal_{i}.csv', header=None)\n\nfor i in range(1, 501):\n    globals()[f\"data_unbalance_i_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/unbalance_6/unbalance_i_{i}.csv', header=None)\n\nfor i in range(1, 501):\n    globals()[f\"data_unbalance_ii_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/unbalance_27/unbalance_ii_{i}.csv', header=None)\n\n\n\nfor i in range(1, 1001):\n    globals()[f\"data_misalignment_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/misalignment/misalignment_{i}.csv', header=None)\n    \n\nfor i in range(1, 1001):\n    globals()[f\"data_bearing_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/bearing/bearing_{i}.csv', header=None)\n\n\n\nprint('DATASET LOADED')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize which axis exhibits the highest amplitude.\n\n\ndf = globals()[\"data_unbalance_ii_100\"]\n\ntime = df.iloc[:, 0]\naxis_x = df.iloc[:, 1]\naxis_y = df.iloc[:, 2]\naxis_z = df.iloc[:, 3]\n\nplt.figure(figsize=(12, 6))\nplt.plot(time, axis_x, label='X axis')\nplt.plot(time, axis_y, label='Y axis')\nplt.plot(time, axis_z, label='Z axis')\nplt.title('Vibration in 3 axis - Unbalance II')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fs = 20000\n\nwindow_time = 1\nwindow = fs * window_time  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Divide the raw signal in samples of 1 sec and labeling each sample","metadata":{}},{"cell_type":"code","source":"def get_features(data, label):\n    n = int(np.floor(len(data)/window))\n    data = data[:int(n)*window]\n    X = data.values.reshape((n, window))\n    y = np.ones(n)*labels[label]\n    return X,y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlabels = {'normal':0, 'unbalance_1':1, 'unbalance_2':2,'misaligment':3, 'bearing_fault':4}\naxis = 2\n\n\nX_list = []\nY_list = []\n\n\nfor i in range(1, 1001):\n    globals()[f'X_normal_{i}'], globals()[f'y_normal_{i}'] = get_features(globals()[f'data_normal_{i}'][axis], \"normal\")\n    X_list.append(globals()[f\"X_normal_{i}\"])\n    Y_list.append(globals()[f\"y_normal_{i}\"])\n\n\nfor i in range(1, 501):\n    globals()[f'X_unbalance_i_{i}'], globals()[f'y_unbalance_i_{i}'] = get_features(globals()[f'data_unbalance_i_{i}'][axis], \"unbalance_1\")\n    X_list.append(globals()[f\"X_unbalance_i_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_i_{i}\"])\n    \nfor i in range(1, 501):\n    globals()[f'X_unbalance_ii_{i}'], globals()[f'y_unbalance_ii_{i}'] = get_features(globals()[f'data_unbalance_ii_{i}'][axis], \"unbalance_2\")\n    X_list.append(globals()[f\"X_unbalance_ii_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_ii_{i}\"])\n\n\nfor i in range(1, 1001):\n    globals()[f'X_misaligment_{i}'], globals()[f'y_misaligment_{i}'] = get_features(globals()[f'data_misalignment_{i}'][axis], \"misaligment\")\n    X_list.append(globals()[f\"X_misaligment_{i}\"])\n    Y_list.append(globals()[f\"y_misaligment_{i}\"])\n\nfor i in range(1, 1001):\n    globals()[f'X_bearing_{i}'], globals()[f'y_bearing_{i}'] = get_features(globals()[f'data_bearing_{i}'][axis], \"bearing_fault\")\n    X_list.append(globals()[f\"X_bearing_{i}\"])\n    Y_list.append(globals()[f\"y_bearing_{i}\"])\n\n\nX=np.concatenate(X_list)\nY=np.concatenate(Y_list)\n\n\nprint(X.shape, Y.shape)\n\nprint('Done')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Histogram used to visualize the number of samples per class (to verify whether the dataset is balanced).\n\ncustom_labels = [\n    \"Normal\",\n    \"Unb. I\",\n    \"Unb. II\",\n    \"Misalig.\",\n    \"Bearings\"\n]\n\n# Criar histograma\nplt.figure(figsize=(8,5))\nplt.hist(Y, bins=np.arange(len(labels)+1)-0.5, edgecolor='black', rwidth=0.8)\n\n# Ajustar eixos e rÃ³tulos\nplt.xticks(range(len(labels)), custom_labels, rotation=0)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Absolute Frequency\")\nplt.title(\"Class Distribution for Dataset II\")\n\nplt.grid(axis='y', linestyle='--', alpha=0.6)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Input Dataset III","metadata":{}},{"cell_type":"code","source":"\nfor i in range(1, 50):\n    globals()[f\"data_normal_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/normal/normal_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\nfor i in range(1, 49):\n    globals()[f\"data_unbalance_i_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_i/unbalance_6_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\nfor i in range(1, 49):\n    globals()[f\"data_unbalance_ii_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_ii/unbalance_20_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\nfor i in range(1, 49):\n    globals()[f\"data_unbalance_iii_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_iii/unbalance_35_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\n\nfor i in range(1, 50):\n    globals()[f\"data_misalignment_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/misalignment/misalignment_{i}.csv', header=None,sep = '[;,]', engine = 'python')\n\n\nfor i in range(1, 40):\n    globals()[f\"data_unbalance_misaligment_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_misalignment/unbalance_misalignment_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\n\n\n\nprint('DATASET LOADED')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize which axis exhibits the highest amplitude.\n\n\ndf = globals()[\"data_unbalance_ii_42\"]\n\naxis_time = df.iloc[:, 0]\naxis_x = df.iloc[:, 5]\naxis_y = df.iloc[:, 7]\naxis_z = df.iloc[:, 6]\n\nplt.figure(figsize=(12, 6))\nplt.plot(time, axis_x, label='X axis')\nplt.plot(time, axis_y, label='Y axis')\nplt.plot(time, axis_z, label='Z axis')\nplt.title('Vibration in 3 axis - Unbalance II')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fs = 50000\n\nwindow_time = 1                # Janela de 1 segundo\nwindow = fs * window_time ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef get_features(data, label):\n    n = int(np.floor(len(data)/window))\n    data = data[:int(n)*window]\n    X = data.values.reshape((n, window))\n    y = np.ones(n)*labels[label]\n    return X,y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlabels = {'normal':0, 'unbalance_1':1, 'unbalance_2':2, 'unbalance_3':3, 'misaligment':4, 'unbalance_misaligment':5}\naxis = 6\n\n\nX_list = []\nY_list = []\n\n\nfor i in range(1, 50):\n    globals()[f'X_normal_{i}'], globals()[f'y_normal_{i}'] = get_features(globals()[f'data_normal_{i}'][axis], \"normal\")\n    X_list.append(globals()[f\"X_normal_{i}\"])\n    Y_list.append(globals()[f\"y_normal_{i}\"])\n\nfor i in range(1, 49):\n    globals()[f'X_unbalance_i_{i}'], globals()[f'y_unbalance_i_{i}'] = get_features(globals()[f'data_unbalance_i_{i}'][axis], \"unbalance_1\")\n    X_list.append(globals()[f\"X_unbalance_i_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_i_{i}\"])\n    \nfor i in range(1, 49):\n    globals()[f'X_unbalance_ii_{i}'], globals()[f'y_unbalance_ii_{i}'] = get_features(globals()[f'data_unbalance_ii_{i}'][axis], \"unbalance_2\")\n    X_list.append(globals()[f\"X_unbalance_ii_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_ii_{i}\"])\n\nfor i in range(1, 49):\n    globals()[f'X_unbalance_iii_{i}'], globals()[f'y_unbalance_iii_{i}'] = get_features(globals()[f'data_unbalance_iii_{i}'][axis], \"unbalance_3\")\n    X_list.append(globals()[f\"X_unbalance_iii_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_iii_{i}\"])\n\n\nfor i in range(1, 50):\n    globals()[f'X_misalignment_{i}'], globals()[f'y_misalignment_{i}'] = get_features(globals()[f'data_misalignment_{i}'][axis], \"misaligment\")\n    X_list.append(globals()[f\"X_misalignment_{i}\"])\n    Y_list.append(globals()[f\"y_misalignment_{i}\"])\n\nfor i in range(1, 40):\n    globals()[f'X_unbalance_misaligment_{i}'], globals()[f'y_unbalance_misaligment_{i}'] = get_features(globals()[f'data_unbalance_misaligment_{i}'][axis], \"unbalance_misaligment\")\n    X_list.append(globals()[f\"X_unbalance_misaligment_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_misaligment_{i}\"])\n\n\n\nX=np.concatenate(X_list)\nY=np.concatenate(Y_list)\n\n\nprint(X.shape, Y.shape)\n\nprint('Done')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Histogram used to visualize the number of samples per class (to verify whether the dataset is balanced).\n\ncustom_labels = [\n    \"Normal\",\n    \"Unb. I\",\n    \"Unb. II\",\n    \"Unb. III\",\n    \"Misalig.\",\n    \"Unb. II + Misalig.\"\n]\n\n# Criar histograma\nplt.figure(figsize=(8,5))\nplt.hist(Y, bins=np.arange(len(labels)+1)-0.5, edgecolor='black', rwidth=0.8)\n\n# Ajustar eixos e rÃ³tulos\nplt.xticks(range(len(labels)), custom_labels, rotation=0)\nplt.xlabel(\"Class\")\nplt.ylabel(\"Absolute Frequency\")\nplt.title(\"Class Distribution for Dataset III\")\n\nplt.grid(axis='y', linestyle='--', alpha=0.6)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Train, validation and test dataset Split","metadata":{}},{"cell_type":"markdown","source":"##### 80 % Train and  20% Test","metadata":{}},{"cell_type":"code","source":"X, Y = shuffle(X, Y, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 20% of the data used for testing.\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n\nprint(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 01 - SVM with raw signal (with no feature extraction)","metadata":{}},{"cell_type":"code","source":"#Signal Standardization\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Signal normalization\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Grid search (No Cross-validation)\n\nstart_time = time.time()\n\n# Grid search hiperparameters\nparam_grid = [\n    {'kernel': 'linear', 'C': C}\n    for C in [0.1, 1, 10, 100]\n] + [\n    {'kernel': 'rbf', 'C': C, 'gamma': gamma}\n    for C in [0.1, 1, 10, 100]\n    for gamma in [0.001, 0.01, 0.1, 'scale']\n] + [\n    {'kernel': 'poly', 'C': C, 'degree': d, 'gamma': gamma}\n    for C in [0.1, 1, 10]\n    for d in [2, 3, 4]\n    for gamma in [0.01, 0.1]\n]\n\n\nresults = []\n\n\nfor params in param_grid:\n    model = SVC(**params)\n    model.fit(X_train_scaled, Y_train)\n    Y_pred = model.predict(X_test_scaled)\n\n    acc = accuracy_score(Y_test, Y_pred)\n    f1 = f1_score(Y_test, Y_pred, average=None)\n    report = classification_report(Y_test, Y_pred)\n\n    results.append({\n        'params': params,\n        'accuracy': acc,\n        'f1_score': f1,\n        'report':report\n    })\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nresults_sorted = sorted(results, key=lambda x: x['accuracy'], reverse=True)\nbest = results_sorted[0]\n\nreport = classification_report(Y_test, Y_pred)\n\n\nprint(\"Melhores parÃ¢metros encontrados:\", best['params'])\nprint(\"Accuracy:\", best['accuracy'])\nprint(\"F1-score per classe:\", f1)\nprint(\"Tempo de treino (s):\", elapsed_time)\nprint(report)\nprint(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train model without grid search\n\nstart_time = time.time()\n\n#model = SVC(kernel='rbf', C=10, gamma = 'scale')\n#model = SVC(kernel='poly', C=1, gamma = 0.01, degree = 2)\nmodel = SVC(kernel='rbf', C=100, gamma = 'scale')\n\nmodel.fit(X_train, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = model.predict(X_test)\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n# conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=True)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Real Class')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve and AUC value\n\n#Binarize the labels.\nclasses = list(labels.values())\nY_test_bin = label_binarize(Y_test, classes=classes)\n\nY_score = model.decision_function(X_test_scaled)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nn_classes = len(classes)\n\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\n\nplt.figure(figsize=(8, 6))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'darkgreen', 'crimson'])\n\n\nclass_names = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n\n\nfor i, (color, name) in enumerate(zip(colors, class_names)):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f\"{name} (AUC = {roc_auc[i]:.2f})\")\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Specificity)')\nplt.title('ROC Curves')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 02 - SVM with statistical features extraction","metadata":{}},{"cell_type":"markdown","source":"### Feature extraction","metadata":{}},{"cell_type":"code","source":"def extract_features(signal):\n    features = []\n    features.append(np.max(signal))     # maximum\n    features.append(np.min(signal))     # minimum\n    features.append(np.max(np.abs(signal))) #Peak\n    features.append(np.ptp(signal))         # #Peak-to-peak\n    features.append(np.mean(signal))        # mean\n    features.append(np.std(signal))     # standart deviation\n    features.append(np.sqrt(np.mean(signal**2)))  # RMS\n    rms = np.sqrt(np.mean(signal**2)) # RMS\n    peak_amplitude = np.max(np.abs(signal)) #Peak\n    features.append(peak_amplitude / rms if rms != 0 else 0) #cres factor\n    features.append(kurtosis(signal))                        #Kurtosis\n    features.append(skew(signal))                       #Skewness             \n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_features = []\nX_test_features = []\n\nfor signal in X_train:\n    featured_signal = extract_features(signal)\n    X_train_features.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features(signal)\n    X_test_features.append(featured_signal)    \n\n\nX_train_features = np.array(X_train_features) \nX_test_features =  np.array(X_test_features) \n\n\nprint(X_train_features.shape)\nprint(X_test_features.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Grid Search (No Cross-validation)\n\nstart_time = time.time()\n\nparam_grid = [\n    {'kernel': 'linear', 'C': C}\n    for C in [0.1, 1, 10, 100]\n] + [\n    {'kernel': 'rbf', 'C': C, 'gamma': gamma}\n    for C in [0.1, 1, 10, 100]\n    for gamma in [0.001, 0.01, 0.1, 'scale']\n] + [\n    {'kernel': 'poly', 'C': C, 'degree': d, 'gamma': gamma}\n    for C in [0.1, 1, 10]\n    for d in [2, 3, 4]\n    for gamma in [0.01, 0.1]\n]\n\nresults = []\n\nfor params in param_grid:\n    model = SVC(**params)\n    model.fit(X_train_features, Y_train)\n    Y_pred = model.predict(X_test_features)\n\n    acc = accuracy_score(Y_test, Y_pred)\n    f1_weighted = f1_score(Y_test, Y_pred, average='weighted')\n    f1_per_class = f1_score(Y_test, Y_pred, average=None)\n\n    results.append({\n        'params': params,\n        'accuracy': acc,\n        'f1_weighted': f1_weighted,\n        'f1_per_class': f1_per_class\n    })\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nresults_sorted = sorted(results, key=lambda x: x['f1_weighted'], reverse=True)\nbest = results_sorted[0]\n\nbest_model = SVC(**best['params'])\nbest_model.fit(X_train_features, Y_train)\nbest_pred = best_model.predict(X_test_features)\nreport = classification_report(Y_test, best_pred)\n\nprint(\"Melhores parÃ¢metros encontrados:\", best['params'])\nprint(\"Accuracy:\", best['accuracy'])\nprint(\"F1-score por classe:\", best['f1_per_class'])\nprint(\"F1-score ponderado:\", best['f1_weighted'])\nprint(\"Tempo de treino (s):\", elapsed_time)\nprint(\"\\nClassification Report (melhor modelo):\\n\", report)\nprint(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train model without grid search\n\nstart_time = time.time()\n\n#model = SVC(kernel='rbf', C=100, gamma = 0.1) #dataset I, II e III\nmodel = SVC(kernel='rbf', C=100, gamma = 'scale')\n\nmodel.fit(X_train_features, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = model.predict(X_test_features)\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=True)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Real Class')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve and AUC value\n\nclasses = list(labels.values())\nY_test_bin = label_binarize(Y_test, classes=classes)\n\nY_score = model.decision_function(X_test_features)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nn_classes = len(classes)\n\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(8, 6))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'darkgreen', 'crimson'])\n\nclass_names = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n\n\nfor i, (color, name) in enumerate(zip(colors, class_names)):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f\"{name} (AUC = {roc_auc[i]:.2f})\")\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Specificity)')\nplt.title('ROC Curves')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 03 - SVM with statistical features extraction and PCA","metadata":{}},{"cell_type":"markdown","source":"### Feature extraction","metadata":{}},{"cell_type":"code","source":"def extract_features(signal):\n    features = []\n    features.append(np.max(signal))     # maximum\n    features.append(np.min(signal))     # minimum\n    features.append(np.max(np.abs(signal))) #Peak\n    features.append(np.ptp(signal))         # #Peak-to-peak\n    features.append(np.mean(signal))    # mean\n    features.append(np.std(signal))     # standart deviation\n    features.append(np.sqrt(np.mean(signal**2)))  # RMS\n    rms = np.sqrt(np.mean(signal**2)) # RMS\n    peak_amplitude = np.max(np.abs(signal)) #Peak\n    features.append(peak_amplitude / rms if rms != 0 else 0) #cres factor\n    features.append(kurtosis(signal))                        #Kurtosis\n    features.append(skew(signal))                       #Skewness             \n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_features = []\nX_test_features = []\n\nfor signal in X_train:\n    featured_signal = extract_features(signal)\n    X_train_features.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features(signal)\n    X_test_features.append(featured_signal)    \n\n\nX_train_features = np.array(X_train_features) \nX_test_features =  np.array(X_test_features) \n\n\nprint(X_train_features.shape)\nprint(X_test_features.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check whether accuracy varies with the number of principal components (PCs) applied.\n\nresults = []\n\nfor n_pca_components in range(2,11):\n    \n    pca = PCA(n_components = n_pca_components) \n    X_train_features_pca = pca.fit_transform(X_train_features)\n    X_test_features_pca = pca.transform(X_test_features)\n\n\n    model = SVC(kernel='rbf', C=100, gamma = 0.1)\n    model.fit(X_train_features_pca, Y_train)\n    Y_pred = model.predict(X_test_features_pca)\n\n    acc = accuracy_score(Y_test, Y_pred)\n    \n    results.append((n_pca_components ,acc))\n\n    print(f\"n_components={n_pca_components} -> Accuracy = {acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot showing the relationship between the number of principal components (PCs) and model accuracy.\n\nn_principal_components, accuracies = zip(*results)\n\nplt.figure(figsize=(8, 5))\nplt.plot(n_principal_components, accuracies, marker='o')\nplt.title(\"Support Vector Machines Accuracy vs. Number of Principal Components\")\nplt.xlabel(\"Number of Principal Components (PCs)\")\nplt.ylabel(\"SVM model accuracy\")\nplt.xlim(2,10)\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply PCA\n\nn_of_pca_components = 6   # nÂºo of PCA components < n_features\n\npca = PCA(n_components = n_of_pca_components)\n\nX_train_features_pca = pca.fit_transform(X_train_features)\n\nX_test_features_pca = pca.transform(X_test_features)\n\n\nprint(\"Shape after PCA:\", X_train_features_pca.shape)\n\nprint(pca.components_.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train model without grid search\n\nstart_time = time.time()\n\n\n# model = SVC(kernel='rbf', C=100, gamma = 0.1) #dataset I, II e III\nmodel = SVC(kernel='rbf', C=100, gamma = 'scale')\n\nmodel.fit(X_train_features_pca, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = model.predict(X_test_features_pca)\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n#conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\nconf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=True)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Real Class')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve and AUC value\n\nclasses = list(labels.values())\nY_test_bin = label_binarize(Y_test, classes=classes)\n\nY_score = model.decision_function(X_test_features_pca)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nn_classes = len(classes)\n\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\nplt.figure(figsize=(8, 6))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'darkgreen', 'crimson'])\n\nclass_names = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n\nfor i, (color, name) in enumerate(zip(colors, class_names)):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f\"{name} (AUC = {roc_auc[i]:.2f})\")\n\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Specificity)')\nplt.title('ROC Curves')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Grid Search (No Cross-validation)\n\nstart_time = time.time()\n\nparam_grid = [\n    {'kernel': 'linear', 'C': C}\n    for C in [0.1, 1, 10, 100]\n] + [\n    {'kernel': 'rbf', 'C': C, 'gamma': gamma}\n    for C in [0.1, 1, 10, 100]\n    for gamma in [0.001, 0.01, 0.1, 'scale']\n] + [\n    {'kernel': 'poly', 'C': C, 'degree': d, 'gamma': gamma}\n    for C in [0.1, 1, 10]\n    for d in [2, 3, 4]\n    for gamma in [0.01, 0.1]\n]\n\nresults = []\n\nfor params in param_grid:\n    model = SVC(**params)\n    model.fit(X_train_features_pca, Y_train)\n    Y_pred = model.predict(X_test_features_pca)\n\n    acc = accuracy_score(Y_test, Y_pred)\n    f1_weighted = f1_score(Y_test, Y_pred, average='weighted')\n    f1_per_class = f1_score(Y_test, Y_pred, average=None)\n\n    results.append({\n        'params': params,\n        'accuracy': acc,\n        'f1_weighted': f1_weighted,\n        'f1_per_class': f1_per_class\n    })\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nresults_sorted = sorted(results, key=lambda x: x['f1_weighted'], reverse=True)\nbest = results_sorted[0]\n\nbest_model = SVC(**best['params'])\nbest_model.fit(X_train_features_pca, Y_train)\nbest_pred = best_model.predict(X_test_features_pca)\nreport = classification_report(Y_test, best_pred)\n\nprint(\"Melhores parÃ¢metros encontrados:\", best['params'])\nprint(\"Accuracy:\", best['accuracy'])\nprint(\"F1-score por classe:\", best['f1_per_class'])\nprint(\"F1-score ponderado:\", best['f1_weighted'])\nprint(\"Tempo de treino (s):\", elapsed_time)\nprint(\"\\nClassification Report (melhor modelo):\\n\", report)\nprint(results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 04 - SVM with FFT features extraction","metadata":{}},{"cell_type":"markdown","source":"### Extract frequency features (FFT)","metadata":{}},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft = []\nX_test_fft = []\n\nfor signal in X_train:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft.append(featured_signal)    \n    \nX_train_fft =  np.array(X_train_fft)   \nX_test_fft = np.array(X_test_fft)\n\n\nprint(X_train_fft.shape)\nprint(X_test_fft.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Grid search (No Cross-validation)\n\nstart_time = time.time()\n\nparam_grid = [\n    {'kernel': 'linear', 'C': C}\n    for C in [0.1, 1, 10, 100]\n] + [\n    {'kernel': 'rbf', 'C': C, 'gamma': gamma}\n    for C in [0.1, 1, 10, 100]\n    for gamma in [0.001, 0.01, 0.1, 'scale']\n] + [\n    {'kernel': 'poly', 'C': C, 'degree': d, 'gamma': gamma}\n    for C in [0.1, 1, 10]\n    for d in [2, 3, 4]\n    for gamma in [0.01, 0.1]\n]\n\nresults = []\n\nfor params in param_grid:\n    model = SVC(**params)\n    model.fit(X_train_fft, Y_train)\n    Y_pred = model.predict(X_test_fft)\n\n    acc = accuracy_score(Y_test, Y_pred)\n    f1_weighted = f1_score(Y_test, Y_pred, average='weighted')\n    f1_per_class = f1_score(Y_test, Y_pred, average=None)\n\n    results.append({\n        'params': params,\n        'accuracy': acc,\n        'f1_weighted': f1_weighted,\n        'f1_per_class': f1_per_class\n    })\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nresults_sorted = sorted(results, key=lambda x: x['f1_weighted'], reverse=True)\nbest = results_sorted[0]\n\n\nbest_model = SVC(**best['params'])\nbest_model.fit(X_train_fft, Y_train)\nbest_pred = best_model.predict(X_test_fft)\nreport = classification_report(Y_test, best_pred)\n\n\nprint(\"Melhores parÃ¢metros encontrados:\", best['params'])\nprint(\"Accuracy:\", best['accuracy'])\nprint(\"F1-score por classe:\", best['f1_per_class'])\nprint(\"F1-score ponderado:\", best['f1_weighted'])\nprint(\"Tempo de treino (s):\", elapsed_time)\nprint(\"\\nClassification Report (melhor modelo):\\n\", report)\nprint(results)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train model without grid search\n\nstart_time = time.time()\n\n#model = SVC(kernel='rbf', C=100, gamma = 0.001) #dataset I\n#model = SVC(kernel='poly', C=1, gamma = 0.01, degree = 2) \n# model = SVC(kernel='linear', C=0.1)   #dataset III\n\nmodel = SVC(kernel='rbf', C=100, gamma = 'scale')\n\n\n\nmodel.fit(X_train_fft, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = model.predict(X_test_fft)\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=True)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Real Class')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve and AUC value  (Apenas para Dataset I)\n\nclasses = list(labels.values())  # [0, 1, 2, 3, 4]\nY_test_bin = label_binarize(Y_test, classes=classes)\n\nY_score = model.decision_function(X_test_fft)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nn_classes = len(classes)\n\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\nplt.figure(figsize=(8, 6))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'darkgreen', 'crimson'])\n\nclass_names = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n\nfor i, (color, name) in enumerate(zip(colors, class_names)):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f\"{name} (AUC = {roc_auc[i]:.2f})\")\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Specificity)')\nplt.title('ROC Curves')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 05 - SVM with noisy data (Train Dataset noisy + Test Dataset not noisy)","metadata":{}},{"cell_type":"code","source":"def add_white_noise(signal, snr_db):\n    signal_power = np.mean(signal**2)\n    snr_linear = 10 ** (snr_db / 10)\n    noise_power = signal_power / snr_linear\n    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n    return signal + noise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_train]) \n\n# snr_db=30 â Almost noise-free.\n# snr_db=10 â Moderate noise.\n# snr_db=5 â High noise.\n\nprint(X_train_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft_noisy = []\nX_test_fft = []\n\nfor signal in X_train_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft_noisy.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft.append(featured_signal)    \n    \nX_train_fft_noisy =  np.array(X_train_fft_noisy)   \nX_test_fft = np.array(X_test_fft)\n\n\nprint(X_train_fft_noisy.shape)\nprint(X_test_fft.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train model without grid search\n\nstart_time = time.time()\n\n#model = SVC(kernel='rbf', C=100, gamma = 0.001)\nmodel = SVC(kernel='rbf', C=100, gamma = 'scale')\n\nmodel.fit(X_train_fft_noisy, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = model.predict(X_test_fft)\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n# conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 06 - SVM with noisy data (Train Dataset not noisy + Test Dataset noisy)","metadata":{}},{"cell_type":"code","source":"def add_white_noise(signal, snr_db):\n    signal_power = np.mean(signal**2)\n    snr_linear = 10 ** (snr_db / 10)\n    noise_power = signal_power / snr_linear\n    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n    return signal + noise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_test]) \n\nprint(X_test_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft = []\nX_test_fft_noisy = []\n\nfor signal in X_train:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft.append(featured_signal)\n    \nfor signal in X_test_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft_noisy.append(featured_signal)    \n    \nX_train_fft =  np.array(X_train_fft)   \nX_test_fft_noisy = np.array(X_test_fft_noisy)\n\n\nprint(X_train_fft.shape)\nprint(X_test_fft_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train model without grid search\n\nstart_time = time.time()\n\n#model = SVC(kernel='rbf', C=100, gamma = 0.001)\nmodel = SVC(kernel='rbf', C=100, gamma = 'scale')\n\nmodel.fit(X_train_fft, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = model.predict(X_test_fft_noisy)\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n# conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 07 - SVM with noisy data (Train Dataset noisy + Test Dataset noisy)","metadata":{}},{"cell_type":"code","source":"def add_white_noise(signal, snr_db):\n    signal_power = np.mean(signal**2)\n    snr_linear = 10 ** (snr_db / 10)\n    noise_power = signal_power / snr_linear\n    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n    return signal + noise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_train]) \nX_test_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_test]) \n\nprint(X_train_noisy.shape)\nprint(X_test_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude\n ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft_noisy = []\nX_test_fft_noisy = []\n\nfor signal in X_train_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft_noisy.append(featured_signal)\n    \nfor signal in X_test_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft_noisy.append(featured_signal)    \n    \nX_train_fft_noisy =  np.array(X_train_fft_noisy)   \nX_test_fft_noisy = np.array(X_test_fft_noisy)\n\n\nprint(X_train_fft_noisy.shape)\nprint(X_test_fft_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train model without grid search\n\nstart_time = time.time()\n\n#model = SVC(kernel='rbf', C=100, gamma = 0.001)\nmodel = SVC(kernel='rbf', C=100, gamma = 'scale')\n\nmodel.fit(X_train_fft_noisy, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = model.predict(X_test_fft_noisy)\n\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n# conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}