{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11869742,"sourceType":"datasetVersion","datasetId":7459206},{"sourceId":12537171,"sourceType":"datasetVersion","datasetId":7914863},{"sourceId":12564627,"sourceType":"datasetVersion","datasetId":7934346}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom scipy.stats import kurtosis, skew\nfrom sklearn.metrics import roc_curve, auc\nfrom itertools import cycle\n\nfrom scipy.fft import fft\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nimport seaborn as sns\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.preprocessing import label_binarize\n\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#File names\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Input Dataset I","metadata":{}},{"cell_type":"code","source":"\n\ndata0D = pd.read_csv('/kaggle/input/vibration-dataset-1/0D.csv')\ndata1D = pd.read_csv('/kaggle/input/vibration-dataset-1/1D.csv')\ndata2D = pd.read_csv('/kaggle/input/vibration-dataset-1/2D.csv')\ndata3D = pd.read_csv('/kaggle/input/vibration-dataset-1/3D.csv')\ndata4D = pd.read_csv('/kaggle/input/vibration-dataset-1/4D.csv')\n\ndata0E = pd.read_csv('/kaggle/input/vibration-dataset-1/0E.csv')\ndata1E = pd.read_csv('/kaggle/input/vibration-dataset-1/1E.csv')\ndata2E = pd.read_csv('/kaggle/input/vibration-dataset-1/2E.csv')\ndata3E = pd.read_csv('/kaggle/input/vibration-dataset-1/3E.csv')\ndata4E = pd.read_csv('/kaggle/input/vibration-dataset-1/4E.csv')\n\n\n\nprint('DATASET LOADED')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The signal was initialized from 20 seconds onward to eliminate the initial transient phase.\n\nfs = 4096\ninitial_time = 20 * fs  \n\n\n# Reset index\ndata0D = data0D.iloc[initial_time:].reset_index(drop=True)\ndata1D = data1D.iloc[initial_time:].reset_index(drop=True)\ndata2D = data2D.iloc[initial_time:].reset_index(drop=True)\ndata3D = data3D.iloc[initial_time:].reset_index(drop=True)\ndata4D = data4D.iloc[initial_time:].reset_index(drop=True)\n\n\ndata0E = data0E.iloc[initial_time:].reset_index(drop=True)\ndata1E = data1E.iloc[initial_time:].reset_index(drop=True)\ndata2E = data2E.iloc[initial_time:].reset_index(drop=True)\ndata3E = data3E.iloc[initial_time:].reset_index(drop=True)\ndata4E = data4E.iloc[initial_time:].reset_index(drop=True)\n\n\nprint('Done')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# One-second window\n\nwindow_time = 1\nwindow = fs * window_time  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Divide the raw signal in samples of 1 sec and labeling each sample","metadata":{}},{"cell_type":"code","source":"# Extracts signal segments of the specified window size.\n\ndef get_features(data, label):\n    n = int(np.floor(len(data)/window))\n    data = data[:int(n)*window]\n    X = data.values.reshape((n, window))\n    y = np.ones(n)*labels[label]\n    return X,y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels = {'no_unbalance':0, 'unbalance_1':1, 'unbalance_2':2,'unbalance_3':3, 'unbalance_4':4}\nsensor = 'Vibration_2'\n\n\nX0D, y0D = get_features(data0D[sensor], \"no_unbalance\")\nX1D, y1D = get_features(data1D[sensor], \"unbalance_1\")\nX2D, y2D = get_features(data2D[sensor], \"unbalance_2\")\nX3D, y3D = get_features(data3D[sensor], \"unbalance_3\")\nX4D, y4D = get_features(data4D[sensor], \"unbalance_4\")\n\n\nX0E, y0E = get_features(data0E[sensor], \"no_unbalance\")\nX1E, y1E = get_features(data1E[sensor], \"unbalance_1\")\nX2E, y2E = get_features(data2E[sensor], \"unbalance_2\")\nX3E, y3E = get_features(data3E[sensor], \"unbalance_3\")\nX4E, y4E = get_features(data4E[sensor], \"unbalance_4\")\n\n\nX=np.concatenate([X0D, X1D, X2D, X3D, X4D, X0E, X1E, X2E, X3E, X4E])\nY=np.concatenate([y0D, y1D, y2D, y3D, y4D, y0E, y1E, y2E, y3E, y4E])\n\n\nprint(X.shape, Y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X4D_1, y4D_1 = get_features(data4D['Vibration_1'], \"unbalance_4\")\nX4D_2, y4D_2 = get_features(data4D['Vibration_2'], \"unbalance_4\")\nX4D_3, y4D_3 = get_features(data4D['Vibration_3'], \"unbalance_4\")\n\nt = np.arange(window) / fs\n\nindice = 5\n\n\np2p = lambda x: float(np.max(x) - np.min(x))\n\nrms = lambda x: float(np.sqrt(np.mean(x**2)))\n\n\np2p_vals = {\n    'Vibration_1': p2p(X4D_1[indice]),\n    'Vibration_2': p2p(X4D_2[indice]),\n    'Vibration_3': p2p(X4D_3[indice]),\n}\n\nrms_vals = {\n    'Vibration_1': rms(X4D_1[indice]),\n    'Vibration_2': rms(X4D_2[indice]),\n    'Vibration_3': rms(X4D_3[indice]),\n}\n\nv1 = X4D_1[indice] - np.mean(X4D_1[indice])\nv2 = X4D_2[indice] - np.mean(X4D_2[indice])\nv3 = X4D_3[indice] - np.mean(X4D_3[indice])\n\n\nplt.figure(figsize=(12,5))\nplt.plot(t, v1, label=f'Vibration_1 (p2p={p2p_vals[\"Vibration_1\"]:.3f},RMS={rms_vals[\"Vibration_1\"]:.3f}))')\nplt.plot(t, v2, label=f'Vibration_2 (p2p={p2p_vals[\"Vibration_2\"]:.3f},RMS={rms_vals[\"Vibration_2\"]:.3f}))')\nplt.plot(t, v3, label=f'Vibration_3 (p2p={p2p_vals[\"Vibration_3\"]:.3f},RMS={rms_vals[\"Vibration_3\"]:.3f}))')\nplt.xlim(0, 1)\nplt.xlabel('Time [s]')\nplt.ylabel('Amplitude')\nplt.title('Dataset I - Comparison of the three-axis vibration signals for a single sample at the 4th degree of unbalance')\nplt.grid(True, alpha=0.3)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\nprint('Pico-a-pico por eixo:', p2p_vals)\nprint('Eixo com maior amplitude:', max(p2p_vals, key=p2p_vals.get))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Input Dataset II","metadata":{}},{"cell_type":"code","source":"\nfor i in range(1, 1001):\n    globals()[f\"data_normal_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/normal/normal_{i}.csv', header=None)\n\nfor i in range(1, 501):\n    globals()[f\"data_unbalance_i_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/unbalance_6/unbalance_i_{i}.csv', header=None)\n\nfor i in range(1, 501):\n    globals()[f\"data_unbalance_ii_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/unbalance_27/unbalance_ii_{i}.csv', header=None)\n\n\n\nfor i in range(1, 1001):\n    globals()[f\"data_misalignment_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/misalignment/misalignment_{i}.csv', header=None)\n    \n\nfor i in range(1, 1001):\n    globals()[f\"data_bearing_{i}\"] = pd.read_csv(f'/kaggle/input/vbl-va001/bearing/bearing_{i}.csv', header=None)\n\n\n\nprint('DATASET LOADED')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize which axis exhibits the highest amplitude.\n\n\ndf = globals()[\"data_unbalance_ii_100\"]\n\ntime = df.iloc[:, 0]\naxis_x = df.iloc[:, 1]\naxis_y = df.iloc[:, 2]\naxis_z = df.iloc[:, 3]\n\nplt.figure(figsize=(12, 6))\nplt.plot(time, axis_x, label='X axis')\nplt.plot(time, axis_y, label='Y axis')\nplt.plot(time, axis_z, label='Z axis')\nplt.title('Vibration in 3 axis - Unbalance II')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fs = 20000\n\nwindow_time = 1\nwindow = fs * window_time  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Divide the raw signal in samples of 1 sec and labeling each sample","metadata":{}},{"cell_type":"code","source":"# Extracts signal segments of the specified window size.\ndef get_features(data, label):\n    n = int(np.floor(len(data)/window))\n    data = data[:int(n)*window]\n    X = data.values.reshape((n, window))\n    y = np.ones(n)*labels[label]\n    return X,y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlabels = {'normal':0, 'unbalance_1':1, 'unbalance_2':2,'misaligment':3, 'bearing_fault':4}\naxis = 2\n\n\nX_list = []\nY_list = []\n\n\nfor i in range(1, 1001):\n    globals()[f'X_normal_{i}'], globals()[f'y_normal_{i}'] = get_features(globals()[f'data_normal_{i}'][axis], \"normal\")\n    X_list.append(globals()[f\"X_normal_{i}\"])\n    Y_list.append(globals()[f\"y_normal_{i}\"])\n\n\nfor i in range(1, 501):\n    globals()[f'X_unbalance_i_{i}'], globals()[f'y_unbalance_i_{i}'] = get_features(globals()[f'data_unbalance_i_{i}'][axis], \"unbalance_1\")\n    X_list.append(globals()[f\"X_unbalance_i_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_i_{i}\"])\n    \nfor i in range(1, 501):\n    globals()[f'X_unbalance_ii_{i}'], globals()[f'y_unbalance_ii_{i}'] = get_features(globals()[f'data_unbalance_ii_{i}'][axis], \"unbalance_2\")\n    X_list.append(globals()[f\"X_unbalance_ii_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_ii_{i}\"])\n\n\n\n\nfor i in range(1, 1001):\n    globals()[f'X_misaligment_{i}'], globals()[f'y_misaligment_{i}'] = get_features(globals()[f'data_misalignment_{i}'][axis], \"misaligment\")\n    X_list.append(globals()[f\"X_misaligment_{i}\"])\n    Y_list.append(globals()[f\"y_misaligment_{i}\"])\n\nfor i in range(1, 1001):\n    globals()[f'X_bearing_{i}'], globals()[f'y_bearing_{i}'] = get_features(globals()[f'data_bearing_{i}'][axis], \"bearing_fault\")\n    X_list.append(globals()[f\"X_bearing_{i}\"])\n    Y_list.append(globals()[f\"y_bearing_{i}\"])\n\n\n\nX=np.concatenate(X_list)\nY=np.concatenate(Y_list)\n\n\nprint(X.shape, Y.shape)\n\nprint('Done')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"# Input Dataset III","metadata":{}},{"cell_type":"code","source":"\nfor i in range(1, 50):\n    globals()[f\"data_normal_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/normal/normal_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\nfor i in range(1, 49):\n    globals()[f\"data_unbalance_i_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_i/unbalance_6_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\nfor i in range(1, 49):\n    globals()[f\"data_unbalance_ii_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_ii/unbalance_20_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\nfor i in range(1, 49):\n    globals()[f\"data_unbalance_iii_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_iii/unbalance_35_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\n\nfor i in range(1, 50):\n    globals()[f\"data_misalignment_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/misalignment/misalignment_{i}.csv', header=None,sep = '[;,]', engine = 'python')\n\n\nfor i in range(1, 40):\n    globals()[f\"data_unbalance_misaligment_{i}\"] = pd.read_csv(f'/kaggle/input/comfaulda/COMFAULDA_v2/unbalance_misalignment/unbalance_misalignment_{i}.csv', header=None, sep = '[;,]', engine = 'python')\n\n\nprint('DATASET LOADED')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize which axis exhibits the highest amplitude.\n\ndf = globals()[\"data_unbalance_ii_42\"]\n\naxis_time = df.iloc[:, 0]\naxis_x = df.iloc[:, 5]\naxis_y = df.iloc[:, 7]\naxis_z = df.iloc[:, 6]\n\nplt.figure(figsize=(12, 6))\nplt.plot(time, axis_x, label='X axis')\nplt.plot(time, axis_y, label='Y axis')\nplt.plot(time, axis_z, label='Z axis')\nplt.title('Vibration in 3 axis - Unbalance II')\nplt.xlabel('Time (s)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fs = 50000\n\nwindow_time = 1 \nwindow = fs * window_time  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracts signal segments of the specified window size.\n\ndef get_features(data, label):\n    n = int(np.floor(len(data)/window))\n    data = data[:int(n)*window]\n    X = data.values.reshape((n, window))\n    y = np.ones(n)*labels[label]\n    return X,y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlabels = {'normal':0, 'unbalance_1':1, 'unbalance_2':2, 'unbalance_3':3, 'misaligment':4, 'unbalance_misaligment':5}\naxis = 6\n\n\nX_list = []\nY_list = []\n\n\nfor i in range(1, 50):\n    globals()[f'X_normal_{i}'], globals()[f'y_normal_{i}'] = get_features(globals()[f'data_normal_{i}'][axis], \"normal\")\n    X_list.append(globals()[f\"X_normal_{i}\"])\n    Y_list.append(globals()[f\"y_normal_{i}\"])\n\nfor i in range(1, 49):\n    globals()[f'X_unbalance_i_{i}'], globals()[f'y_unbalance_i_{i}'] = get_features(globals()[f'data_unbalance_i_{i}'][axis], \"unbalance_1\")\n    X_list.append(globals()[f\"X_unbalance_i_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_i_{i}\"])\n    \nfor i in range(1, 49):\n    globals()[f'X_unbalance_ii_{i}'], globals()[f'y_unbalance_ii_{i}'] = get_features(globals()[f'data_unbalance_ii_{i}'][axis], \"unbalance_2\")\n    X_list.append(globals()[f\"X_unbalance_ii_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_ii_{i}\"])\n\nfor i in range(1, 49):\n    globals()[f'X_unbalance_iii_{i}'], globals()[f'y_unbalance_iii_{i}'] = get_features(globals()[f'data_unbalance_iii_{i}'][axis], \"unbalance_3\")\n    X_list.append(globals()[f\"X_unbalance_iii_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_iii_{i}\"])\n\n\nfor i in range(1, 50):\n    globals()[f'X_misalignment_{i}'], globals()[f'y_misalignment_{i}'] = get_features(globals()[f'data_misalignment_{i}'][axis], \"misaligment\")\n    X_list.append(globals()[f\"X_misalignment_{i}\"])\n    Y_list.append(globals()[f\"y_misalignment_{i}\"])\n\nfor i in range(1, 40):\n    globals()[f'X_unbalance_misaligment_{i}'], globals()[f'y_unbalance_misaligment_{i}'] = get_features(globals()[f'data_unbalance_misaligment_{i}'][axis], \"unbalance_misaligment\")\n    X_list.append(globals()[f\"X_unbalance_misaligment_{i}\"])\n    Y_list.append(globals()[f\"y_unbalance_misaligment_{i}\"])\n\n\n\nX=np.concatenate(X_list)\nY=np.concatenate(Y_list)\n\n\nprint(X.shape, Y.shape)\n\nprint('Done')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Train, validation and test dataset split","metadata":{}},{"cell_type":"markdown","source":"### 80% Train and 20% Test","metadata":{}},{"cell_type":"code","source":"X, Y = shuffle(X, Y, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracts signal segments of the specified window size.\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n\nprint(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 01 - Random Forest with statistical features extraction","metadata":{}},{"cell_type":"markdown","source":"### Feature extraction","metadata":{}},{"cell_type":"code","source":"\ndef extract_features(signal):\n    features = []\n    features.append(np.max(signal))     # maximum\n    features.append(np.min(signal))     # minimum\n    features.append(np.max(np.abs(signal))) #Peak\n    features.append(np.ptp(signal))         # #Peak-to-peak\n    features.append(np.mean(signal))    # mean\n    features.append(np.std(signal))     # standart deviation\n    features.append(np.sqrt(np.mean(signal**2)))  # RMS\n    rms = np.sqrt(np.mean(signal**2)) # RMS\n    peak_amplitude = np.max(np.abs(signal)) #Peak\n    features.append(peak_amplitude / rms if rms != 0 else 0) #cres factor\n    features.append(kurtosis(signal))                        #Kurtosis\n    features.append(skew(signal))                       #Skewness             \n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_features = []\nX_test_features = []\n\nfor signal in X_train:\n    featured_signal = extract_features(signal)\n    X_train_features.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features(signal)\n    X_test_features.append(featured_signal)    \n\n\nX_train_features = np.array(X_train_features) \nX_test_features =  np.array(X_test_features) \n\n\nprint(X_train_features.shape)\nprint(X_test_features.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Test different numbers of trees (from 20 to 300, in steps of 5).\n\nestimators = list(range(20, 301, 5))\naccuracies = []\n\n\nfor n in estimators:\n    clf = RandomForestClassifier(n_estimators=n, criterion='gini', random_state=42)\n    clf.fit(X_train_features, Y_train)\n    Y_pred = clf.predict(X_test_features)\n    acc = accuracy_score(Y_test, Y_pred)\n    accuracies.append(acc)\n\n\nplt.figure(figsize=(8, 5))\nplt.plot(estimators, accuracies, marker='o')\nplt.title('Relationship Between Accuracy and the Number of Decision Trees in the Random Forest')\nplt.xlabel('Nº of Decisions Trees')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\nbest_index = np.argmax(accuracies)\nbest_n_estimators = estimators[best_index]\nbest_accuracy = accuracies[best_index]\n\nprint(f\"Melhor nº de árvores: {best_n_estimators}\")\nprint(f\"Accuracy correspondente: {best_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Find the index corresponding to 240 trees.\nindex_240 = estimators.index(240)\n\n#Retrieve the corresponding accuracy.\naccuracy_240 = accuracies[index_240]\n\nprint(f\"Accuracy with 240 trees: {accuracy_240:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\n\nclf = RandomForestClassifier(n_estimators=240, criterion='gini', max_depth=40, class_weight = None , random_state=42)\nclf.fit(X_train_features, Y_train)\n\n\ntree_depths = [estimator.tree_.max_depth for estimator in clf.estimators_]\n\nmin_depth = np.min(tree_depths)\nmax_depth = np.max(tree_depths)\navg_depth = np.mean(tree_depths)\n\nprint(f\"Profundidade mínima: {min_depth}\")\nprint(f\"Profundidade máxima: {max_depth}\")\nprint(f\"Profundidade média: {avg_depth:.2f}\")\n\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = clf.predict(X_test_features)\n\nprint(confusion_matrix(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize the features importance\n\nimportances = clf.feature_importances_*100\n\nindices = np.argsort(importances)[::-1]\n\n\nfeature_names = [\n    \"Max\", \"Min\", \"Peak\", \"Peak-to-pPeak\", \"Mean\", \"Standard deviation\", \"RMS\", \n    \"Crest factor\", \"Kurtosis\", \"Skewness\"\n]\n\nplt.figure(figsize=(10, 6))\nplt.title(\"Random Forest - Feature Importance\")\n\nbars = plt.bar(range(len(importances)), importances[indices], align='center')\n\nplt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45)\nplt.ylabel(\"Importance (%)\")\nplt.ylim(0, 40)\nplt.grid(axis='y', linestyle='--', alpha=0.6)\n\nfor i, bar in enumerate(bars):\n    height = bar.get_height()\n    plt.text(\n        bar.get_x() + bar.get_width() / 2,  # posição x central da barra\n        height + 0.3,                       # ligeiramente acima da barra\n        f\"{height:.2f}%\",                   # valor com 2 casas decimais e símbolo de %\n        ha='center', va='bottom', fontsize=9\n    )\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n# conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=True)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Real Class')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve and AUC value\n\nclasses = list(labels.values())\nY_test_bin = label_binarize(Y_test, classes=classes)\n\n\nY_score = clf.predict_proba(X_test_features)\n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nn_classes = len(classes)\n\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\nplt.figure(figsize=(8, 6))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'darkgreen', 'crimson'])\n\nclass_names = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n\nfor i, (color, name) in enumerate(zip(colors, class_names)):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f\"{name} (AUC = {roc_auc[i]:.2f})\")\n    \n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Specificity)')\nplt.title('ROC Curves')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 02 - Random Forest with statistical features extraction and PCA","metadata":{}},{"cell_type":"markdown","source":"### Feature extraction","metadata":{}},{"cell_type":"code","source":"def extract_features(signal):\n    features = []\n    features.append(np.max(signal))     # maximum\n    features.append(np.min(signal))     # minimum\n    features.append(np.max(np.abs(signal))) #Peak\n    features.append(np.ptp(signal))         # #Peak-to-peak\n    features.append(np.mean(signal))    # mean\n    features.append(np.std(signal))     # standart deviation\n    features.append(np.sqrt(np.mean(signal**2)))  # RMS\n    rms = np.sqrt(np.mean(signal**2)) # RMS\n    peak_amplitude = np.max(np.abs(signal)) #Peak\n    features.append(peak_amplitude / rms if rms != 0 else 0) #cres factor\n    features.append(kurtosis(signal))                        #Kurtosis\n    features.append(skew(signal))                       #Skewness             \n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_features = []\nX_test_features = []\n\nfor signal in X_train:\n    featured_signal = extract_features(signal)\n    X_train_features.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features(signal)\n    X_test_features.append(featured_signal)    \n    \n \nX_train_features = np.array(X_train_features) \nX_test_features =  np.array(X_test_features)   \n\n\nprint(X_train_features.shape)\nprint(X_test_features.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check whether accuracy varies with the number of principal components (PCs) applied.\n\nresults = []\n\nfor n_pca_components in range(2,11):\n    \n    pca = PCA(n_components = n_pca_components) \n    X_train_pca = pca.fit_transform(X_train_features)\n    X_test_pca = pca.fit_transform(X_test_features)\n\n\n    clf = RandomForestClassifier(n_estimators=225, criterion ='gini', class_weight = None , random_state=42)\n    clf.fit(X_train_pca, Y_train)\n\n    Y_pred = clf.predict(X_test_pca)\n    \n    acc = accuracy_score(Y_test, Y_pred)\n    \n    results.append((n_pca_components ,acc))\n\n    print(f\"n_components={n_pca_components} -> Accuracy = {acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot showing the relationship between the number of principal components (PCs) and model accuracy.\n\nn_principal_components, accuracies = zip(*results)\n\nplt.figure(figsize=(8, 5))\nplt.plot(n_principal_components, accuracies, marker='o')\nplt.title(\"Random Forest Accuracy vs. Number of Principal Components\")\nplt.xlim(2, 10)\nplt.xlabel(\"Number of Principal Components (PCs)\")\nplt.ylabel(\"RF model accuracy\")\nplt.grid(True)\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply PCA\n\nn_of_pca_components = 9   # nºo of PCA components < n_features\n\npca = PCA(n_components = n_of_pca_components) \nX_train_pca = pca.fit_transform(X_train_features)\n\nX_test_pca = pca.fit_transform(X_test_features)\n\n\nprint(\"Shape after PCA:\", X_train_pca.shape)\n\nprint(pca.components_.shape) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test different numbers of trees (20 to 300, steps of 5).\n\nestimators = list(range(20, 301, 5))\naccuracies = []\n\nfor n in estimators:\n    clf = RandomForestClassifier(n_estimators=n, criterion ='gini', random_state=42)\n    clf.fit(X_train_pca, Y_train)\n    Y_pred = clf.predict(X_test_pca)\n    acc = accuracy_score(Y_test, Y_pred)\n    accuracies.append(acc)\n\nplt.figure(figsize=(8, 5))\nplt.plot(estimators, accuracies, marker='o')\nplt.title('Relationship Between Accuracy and the Number of Decision Trees in the Random Forest')\nplt.xlabel('Nº of Decisions Trees')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\nbest_index = np.argmax(accuracies)\nbest_n_estimators = estimators[best_index]\nbest_accuracy = accuracies[best_index]\n\nprint(f\"Melhor nº de árvores: {best_n_estimators}\")\nprint(f\"Accuracy correspondente: {best_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find the index corresponding to 240 trees.\nindex_240 = estimators.index(240)\n\n# Retrieve the corresponding accuracy.\naccuracy_240 = accuracies[index_240]\n\nprint(f\"Accuracy com 240 árvores: {accuracy_240:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\nclf = RandomForestClassifier(n_estimators=240, criterion='gini', max_depth=40, class_weight = None , random_state=42)\nclf.fit(X_train_pca, Y_train)\n\ntree_depths = [estimator.tree_.max_depth for estimator in clf.estimators_]\n\nmin_depth = np.min(tree_depths)\nmax_depth = np.max(tree_depths)\navg_depth = np.mean(tree_depths)\n\nprint(f\"Profundidade mínima: {min_depth}\")\nprint(f\"Profundidade máxima: {max_depth}\")\nprint(f\"Profundidade média: {avg_depth:.2f}\")\n\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nY_pred = clf.predict(X_test_pca)\n\nprint(confusion_matrix(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n#conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\nconf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve and AUC value\n\nclasses = list(labels.values())\nY_test_bin = label_binarize(Y_test, classes=classes)\n\nY_score = clf.predict_proba(X_test_features)\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nn_classes = len(classes)\n\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\n\nplt.figure(figsize=(8, 6))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'darkgreen', 'crimson'])\n\n# Nomes personalizados das classes\nclass_names = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n\nfor i, (color, name) in enumerate(zip(colors, class_names)):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f\"{name} (AUC = {roc_auc[i]:.2f})\")\n\n\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Specificity)')\nplt.title('ROC Curves')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 03 - Random Forest with FFT features extraction","metadata":{}},{"cell_type":"markdown","source":"### Extract frequency features (FFT)","metadata":{}},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft = []\nX_test_fft = []\n\nfor signal in X_train:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft.append(featured_signal)    \n    \nX_train_fft =  np.array(X_train_fft)   \nX_test_fft = np.array(X_test_fft)\n\n\nprint(X_train_fft.shape)\nprint(X_test_fft.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test different numbers of trees (20 to 200, steps of 10)\n\nestimators = list(range(20, 301, 5))\naccuracies_fft = []\n\n\nfor n in estimators:\n    clf = RandomForestClassifier(n_estimators=n, criterion ='gini', random_state=42)\n    clf.fit(X_train_fft, Y_train)\n    Y_pred = clf.predict(X_test_fft)\n    acc = accuracy_score(Y_test, Y_pred)\n    accuracies_fft.append(acc)\n\n\nplt.figure(figsize=(8, 5))\nplt.plot(estimators, accuracies_fft, marker='o')\nplt.title('Accuracy vs Number of Decision Trees in the Random Forest')\nplt.xlabel('Decisions Trees')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\nbest_index = np.argmax(accuracies_fft)\nbest_n_estimators = estimators[best_index]\nbest_accuracy = accuracies_fft[best_index]\n\nprint(f\"Melhor nº de árvores: {best_n_estimators}\")\nprint(f\"Accuracy correspondente: {best_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find the index corresponding to 240 trees.\nindex_240 = estimators.index(240)\n\n# Retrieve the corresponding accuracy.\naccuracy_240 = accuracies[index_240]\n\nprint(f\"Accuracy com 240 árvores: {accuracy_240:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\n\nclf = RandomForestClassifier(n_estimators=240, criterion ='gini', max_depth=40, class_weight = None , random_state=42)\nclf.fit(X_train_fft, Y_train)\n\ntree_depths = [estimator.tree_.max_depth for estimator in clf.estimators_]\n\nmin_depth = np.min(tree_depths)\nmax_depth = np.max(tree_depths)\navg_depth = np.mean(tree_depths)\n\nprint(f\"Profundidade mínima: {min_depth}\")\nprint(f\"Profundidade máxima: {max_depth}\")\nprint(f\"Profundidade média: {avg_depth:.2f}\")\n\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = clf.predict(X_test_fft)\n\nprint(confusion_matrix(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\n#conf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=True)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Real Class')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ROC Curve and AUC value\n\n\nclasses = list(labels.values())\nY_test_bin = label_binarize(Y_test, classes=classes)\n\n\nY_score = clf.predict_proba(X_test_fft)\n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nn_classes = len(classes)\n\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(Y_test_bin[:, i], Y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n\n\nplt.figure(figsize=(8, 6))\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'darkgreen', 'crimson'])\n\nclass_names = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\n\nfor i, (color, name) in enumerate(zip(colors, class_names)):\n    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n             label=f\"{name} (AUC = {roc_auc[i]:.2f})\")\n\n\nplt.plot([0, 1], [0, 1], 'k--', lw=2)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Specificity)')\nplt.title('ROC Curves')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 04 - Random Forest with raw signal (with no feature extraction)","metadata":{}},{"cell_type":"code","source":"#Signal Standardization\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Signal normalization\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test different numbers of trees (20 to 200, steps of 10)\n\nestimators = list(range(20, 301, 5))\naccuracies = []\n\n\nfor n in estimators:\n    clf = RandomForestClassifier(n_estimators=n, criterion ='gini', random_state=42)\n    clf.fit(X_train_scaled, Y_train)\n    Y_pred = clf.predict(X_test_scaled)\n    acc = accuracy_score(Y_test, Y_pred)\n    accuracies.append(acc)\n\n\nbest_index = np.argmax(accuracies)\nbest_n_estimators = estimators[best_index]\nbest_accuracy = accuracies[best_index]\n\nprint(f\"Melhor nº de árvores: {best_n_estimators}\")\nprint(f\"Accuracy correspondente: {best_accuracy:.4f}\")\n\n\nplt.figure(figsize=(8, 5))\nplt.plot(estimators, accuracies, marker='o')\nplt.title('Accuracy vs Number of Decision Trees in the Random Forest')\nplt.xlabel('Decisions Trees)')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nplt.plot(estimators, accuracies, marker='o')\nplt.title('Accuracy vs Number of Decision Trees in the Random Forest')\nplt.xlim([20, 300])\nplt.xlabel('Decisions Trees')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\nbest_index = np.argmax(accuracies)\nbest_n_estimators = estimators[best_index]\nbest_accuracy = accuracies[best_index]\n\nprint(f\"Melhor nº de árvores: {best_n_estimators}\")\nprint(f\"Accuracy correspondente: {best_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find the index corresponding to 240 trees.\nindex_240 = estimators.index(240)\n\n# Retrieve the corresponding accuracy.\naccuracy_240 = accuracies[index_240]\n\nprint(f\"Accuracy com 240 árvores: {accuracy_240:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\n\nclf = RandomForestClassifier(n_estimators=240, criterion ='gini', max_depth=40 , class_weight = None , random_state=42)\nclf.fit(X_train_scaled, Y_train)\n\n\ntree_depths = [estimator.tree_.max_depth for estimator in clf.estimators_]\n\nmin_depth = np.min(tree_depths)\nmax_depth = np.max(tree_depths)\navg_depth = np.mean(tree_depths)\n\nprint(f\"Profundidade mínima: {min_depth}\")\nprint(f\"Profundidade máxima: {max_depth}\")\nprint(f\"Profundidade média: {avg_depth:.2f}\")\n\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = clf.predict(X_test)\n\nprint(confusion_matrix(Y_test_scaled, Y_pred))\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\n# conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\nconf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Misalig.', 'Bearings']\nconf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=True)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 05 - Random Forest with noisy data (Train Dataset noisy + Test Dataset not noisy)","metadata":{}},{"cell_type":"code","source":"def add_white_noise(signal, snr_db):\n    signal_power = np.mean(signal**2)\n    snr_linear = 10 ** (snr_db / 10)\n    noise_power = signal_power / snr_linear\n    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n    return signal + noise\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nX_train_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_train]) \n\n# snr_db=30 → Almost noise-free.\n# snr_db=10 → Moderate noise.\n# snr_db=5 → High noise.\n\nprint(X_train_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Extract frequency features (FFT)","metadata":{}},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft_noisy = []\nX_test_fft = []\n\nfor signal in X_train_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft_noisy.append(featured_signal)\n    \nfor signal in X_test:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft.append(featured_signal)    \n    \nX_train_fft_noisy =  np.array(X_train_fft_noisy)   \nX_test_fft = np.array(X_test_fft)\n\nprint(X_train_fft_noisy.shape)\nprint(X_test_fft.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\n\nclf = RandomForestClassifier(n_estimators=240, criterion ='gini', max_depth=40 , class_weight = None , random_state=42)\nclf.fit(X_train_fft_noisy, Y_train)\n\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = clf.predict(X_test_fft)\n\nprint(confusion_matrix(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\n#conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\nconf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 06 - Random Forest with noisy data (Train Dataset not noisy + Test Dataset noisy)","metadata":{}},{"cell_type":"code","source":"def add_white_noise(signal, snr_db):\n    signal_power = np.mean(signal**2)\n    snr_linear = 10 ** (snr_db / 10)\n    noise_power = signal_power / snr_linear\n    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n    return signal + noise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_test]) \n\nprint(X_test_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Extract frequency features (FFT)","metadata":{}},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft = []\nX_test_fft_noisy = []\n\nfor signal in X_train:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft.append(featured_signal)\n    \nfor signal in X_test_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft_noisy.append(featured_signal)    \n    \nX_train_fft =  np.array(X_train_fft)   \nX_test_fft_noisy = np.array(X_test_fft_noisy)\n\n\nprint(X_train_fft.shape)\nprint(X_test_fft_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\nclf = RandomForestClassifier(n_estimators=240, criterion ='gini', max_depth=40 , class_weight = None , random_state=42)\nclf.fit(X_train_fft, Y_train)\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = clf.predict(X_test_fft_noisy)\n\nprint(confusion_matrix(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\n#conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\nconf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 07 - Random Forest with noisy data (Train Dataset noisy + Test Dataset noisy)","metadata":{}},{"cell_type":"code","source":"def add_white_noise(signal, snr_db):\n    signal_power = np.mean(signal**2)\n    snr_linear = 10 ** (snr_db / 10)\n    noise_power = signal_power / snr_linear\n    noise = np.random.normal(0, np.sqrt(noise_power), signal.shape)\n    return signal + noise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_train]) \nX_test_noisy = np.array([add_white_noise(signal, snr_db=10) for signal in X_test]) \n\n\nprint(X_train_noisy.shape)\nprint(X_test_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Extract frequency features (FFT)","metadata":{}},{"cell_type":"code","source":"def extract_features_fft(signal):\n    fft_vals = fft(signal)\n    fft_magnitude = np.abs(fft_vals)[:len(signal)//2]\n    \n    return fft_magnitude","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_fft_noisy = []\nX_test_fft_noisy = []\n\nfor signal in X_train_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_train_fft_noisy.append(featured_signal)\n    \nfor signal in X_test_noisy:\n    featured_signal = extract_features_fft(signal)\n    X_test_fft_noisy.append(featured_signal)    \n    \nX_train_fft_noisy =  np.array(X_train_fft_noisy)   \nX_test_fft_noisy = np.array(X_test_fft_noisy)\n\n\nprint(X_train_fft_noisy.shape)\nprint(X_test_fft_noisy.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\n\n\nclf = RandomForestClassifier(n_estimators=240, criterion ='gini', max_depth=40 , class_weight = None , random_state=42)\nclf.fit(X_train_noisy, Y_train)\n\n\nend_time = time.time()\nelapsed_time = end_time - start_time\n\n\nprint(\"Time spent in training the model (s):\", elapsed_time)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Y_pred = clf.predict(X_test)\n\nprint(confusion_matrix(Y_test, Y_pred))\nprint(classification_report(Y_test, Y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_matriz = confusion_matrix(Y_test, Y_pred)\n\n#conf_matriz_classes = ['No unb.', 'Unb. I', 'Unb. II', 'Unb. III', 'Unb. IV']\nconf_matriz_classes = ['Normal', 'Unb. I', 'Unb. II','Unb. III', 'Misalig.', 'Unb. II + Misalig.']\n\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matriz, annot=True, fmt='d', cmap='Blues',\n            xticklabels=conf_matriz_classes, yticklabels=conf_matriz_classes,cbar=False)\n\nplt.title('Confusion matrix')\nplt.xlabel('Predicted Classe')\nplt.ylabel('Real Classe')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
